### 定义

大数据处理中的“小文件问题”，是指经过处理并存储在磁盘上的文件很零碎（数量多+每个文件比较小）。这些小文件还很可能存储在不同的分布式机器节点上，导致更大的问题（主要是性能问题）



### 形成原因

设想一个简单场景，有100个文件，每个文件有500行数据，经过 filter()/map() 处理后，每个文件只剩下5行数据，直接存储在对应的分布式节点。这样就形成了100个小文件



### “小文件”有什么问题？

性能问题。



### 解决方法

在 filter()/map() 处理后，如果产生小文件，那么再进行额外一步合并文件操作（如把100个小文件合并成3个文件）